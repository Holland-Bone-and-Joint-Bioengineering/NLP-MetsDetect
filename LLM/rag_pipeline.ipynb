{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q datasets sentence-transformers faiss-cpu accelerate langchain langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/transformers\n",
      "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-c5oi6i44\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-c5oi6i44\n",
      "^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install git+https://github.com/huggingface/transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/nvolk/anaconda3/lib/python3.12/site-packages (4.47.0.dev0)\n",
      "Requirement already satisfied: torch in /home/nvolk/anaconda3/lib/python3.12/site-packages (2.5.1)\n",
      "Requirement already satisfied: accelerate in /home/nvolk/anaconda3/lib/python3.12/site-packages (1.1.1)\n",
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: filelock in /home/nvolk/anaconda3/lib/python3.12/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /home/nvolk/anaconda3/lib/python3.12/site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/nvolk/anaconda3/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/nvolk/anaconda3/lib/python3.12/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/nvolk/anaconda3/lib/python3.12/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/nvolk/anaconda3/lib/python3.12/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /home/nvolk/anaconda3/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /home/nvolk/anaconda3/lib/python3.12/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/nvolk/anaconda3/lib/python3.12/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/nvolk/anaconda3/lib/python3.12/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/nvolk/anaconda3/lib/python3.12/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in /home/nvolk/anaconda3/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/nvolk/anaconda3/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/nvolk/anaconda3/lib/python3.12/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/nvolk/anaconda3/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/nvolk/anaconda3/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/nvolk/anaconda3/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/nvolk/anaconda3/lib/python3.12/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/nvolk/anaconda3/lib/python3.12/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/nvolk/anaconda3/lib/python3.12/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/nvolk/anaconda3/lib/python3.12/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/nvolk/anaconda3/lib/python3.12/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/nvolk/anaconda3/lib/python3.12/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/nvolk/anaconda3/lib/python3.12/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/nvolk/anaconda3/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/nvolk/anaconda3/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/nvolk/anaconda3/lib/python3.12/site-packages (from torch) (3.1.0)\n",
      "Requirement already satisfied: setuptools in /home/nvolk/anaconda3/lib/python3.12/site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/nvolk/anaconda3/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/nvolk/anaconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: psutil in /home/nvolk/anaconda3/lib/python3.12/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/nvolk/anaconda3/lib/python3.12/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/nvolk/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/nvolk/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/nvolk/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/nvolk/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2024.8.30)\n",
      "Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl (122.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.44.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers torch accelerate bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizerFast       # LLM for report classificuing\n",
    "from sentence_transformers import SentenceTransformer       # for embedding model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import DataFrameLoader\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.chains import RetrievalQA\n",
    "from transformers import AutoTokenizer, pipeline#, AutoModelForSeq2SeqGeneration\n",
    "# from transformers import AutoModelForSeq2SeqGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import DataFrameLoader\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.chains import RetrievalQA\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/nvolk/anaconda3/lib/python3.12/site-packages (4.46.3)\n",
      "Requirement already satisfied: filelock in /home/nvolk/anaconda3/lib/python3.12/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/nvolk/anaconda3/lib/python3.12/site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/nvolk/anaconda3/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/nvolk/anaconda3/lib/python3.12/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/nvolk/anaconda3/lib/python3.12/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/nvolk/anaconda3/lib/python3.12/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /home/nvolk/anaconda3/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /home/nvolk/anaconda3/lib/python3.12/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/nvolk/anaconda3/lib/python3.12/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/nvolk/anaconda3/lib/python3.12/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/nvolk/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/nvolk/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/nvolk/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/nvolk/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/nvolk/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/nvolk/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: transformers\n",
      "Version: 4.46.3\n",
      "Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n",
      "Home-page: https://github.com/huggingface/transformers\n",
      "Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n",
      "Author-email: transformers@huggingface.co\n",
      "License: Apache 2.0 License\n",
      "Location: /home/nvolk/anaconda3/lib/python3.12/site-packages\n",
      "Requires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, safetensors, tokenizers, tqdm\n",
      "Required-by: sentence-transformers\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"data/labeled_data_combined_reports.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>imaging_date</th>\n",
       "      <th>reports</th>\n",
       "      <th>image_ct___1</th>\n",
       "      <th>image_ct___2</th>\n",
       "      <th>image_ct___3</th>\n",
       "      <th>combined_reports</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>SHSC-134CJ-PV3YY-9L6O6-PLRA9OVTHG-4JZ2M-UR0UO-...</td>\n",
       "      <td>2010-09-21</td>\n",
       "      <td>Bone Scan(Whole Body)Nuc Med TECHNETIUM MDP BO...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bone Scan(Whole Body)Nuc Med TECHNETIUM MDP BO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>SHSC-134CJ-PV3YY-9L6O6-PLRA9OVTHG-4JZ2M-UR0UO-...</td>\n",
       "      <td>2011-01-13</td>\n",
       "      <td>CT Chest History:\\rFollow-up scan for OZM-011 ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bone Scan(Whole Body)Nuc Med TECHNETIUM MDP BO...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0                                         patient_id imaging_date  \\\n",
       "0          0  SHSC-134CJ-PV3YY-9L6O6-PLRA9OVTHG-4JZ2M-UR0UO-...   2010-09-21   \n",
       "1          1  SHSC-134CJ-PV3YY-9L6O6-PLRA9OVTHG-4JZ2M-UR0UO-...   2011-01-13   \n",
       "\n",
       "                                             reports image_ct___1  \\\n",
       "0  Bone Scan(Whole Body)Nuc Med TECHNETIUM MDP BO...          0.0   \n",
       "1  CT Chest History:\\rFollow-up scan for OZM-011 ...          1.0   \n",
       "\n",
       "   image_ct___2  image_ct___3  \\\n",
       "0           1.0           0.0   \n",
       "1           1.0           0.0   \n",
       "\n",
       "                                    combined_reports  \n",
       "0  Bone Scan(Whole Body)Nuc Med TECHNETIUM MDP BO...  \n",
       "1  Bone Scan(Whole Body)Nuc Med TECHNETIUM MDP BO...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data in df format\n",
    "df_reports = pd.read_csv(filename)\n",
    "df_reports.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>imaging_date</th>\n",
       "      <th>reports</th>\n",
       "      <th>image_ct___1</th>\n",
       "      <th>image_ct___2</th>\n",
       "      <th>image_ct___3</th>\n",
       "      <th>combined_reports</th>\n",
       "      <th>report_and_frac_label</th>\n",
       "      <th>report_and_mets_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>SHSC-134CJ-PV3YY-9L6O6-PLRA9OVTHG-4JZ2M-UR0UO-...</td>\n",
       "      <td>2010-09-21</td>\n",
       "      <td>Bone Scan(Whole Body)Nuc Med TECHNETIUM MDP BO...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bone Scan(Whole Body)Nuc Med TECHNETIUM MDP BO...</td>\n",
       "      <td>Report:\\nBone Scan(Whole Body)Nuc Med TECHNETI...</td>\n",
       "      <td>Report:\\nBone Scan(Whole Body)Nuc Med TECHNETI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>SHSC-134CJ-PV3YY-9L6O6-PLRA9OVTHG-4JZ2M-UR0UO-...</td>\n",
       "      <td>2011-01-13</td>\n",
       "      <td>CT Chest History:\\rFollow-up scan for OZM-011 ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bone Scan(Whole Body)Nuc Med TECHNETIUM MDP BO...</td>\n",
       "      <td>Report:\\nBone Scan(Whole Body)Nuc Med TECHNETI...</td>\n",
       "      <td>Report:\\nBone Scan(Whole Body)Nuc Med TECHNETI...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0                                         patient_id imaging_date  \\\n",
       "0          0  SHSC-134CJ-PV3YY-9L6O6-PLRA9OVTHG-4JZ2M-UR0UO-...   2010-09-21   \n",
       "1          1  SHSC-134CJ-PV3YY-9L6O6-PLRA9OVTHG-4JZ2M-UR0UO-...   2011-01-13   \n",
       "\n",
       "                                             reports image_ct___1  \\\n",
       "0  Bone Scan(Whole Body)Nuc Med TECHNETIUM MDP BO...          0.0   \n",
       "1  CT Chest History:\\rFollow-up scan for OZM-011 ...          1.0   \n",
       "\n",
       "   image_ct___2  image_ct___3  \\\n",
       "0           1.0           0.0   \n",
       "1           1.0           0.0   \n",
       "\n",
       "                                    combined_reports  \\\n",
       "0  Bone Scan(Whole Body)Nuc Med TECHNETIUM MDP BO...   \n",
       "1  Bone Scan(Whole Body)Nuc Med TECHNETIUM MDP BO...   \n",
       "\n",
       "                               report_and_frac_label  \\\n",
       "0  Report:\\nBone Scan(Whole Body)Nuc Med TECHNETI...   \n",
       "1  Report:\\nBone Scan(Whole Body)Nuc Med TECHNETI...   \n",
       "\n",
       "                               report_and_mets_label  \n",
       "0  Report:\\nBone Scan(Whole Body)Nuc Med TECHNETI...  \n",
       "1  Report:\\nBone Scan(Whole Body)Nuc Med TECHNETI...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reports[\"report_and_frac_label\"] = (\n",
    "    \"Report:\\n\" + \n",
    "    df_reports[\"combined_reports\"] + \n",
    "    \"\\n\\nFracture classification:\\n\" + \n",
    "    df_reports[\"image_ct___1\"]\n",
    "    # df_reports[\"image_ct___1\"].apply(lambda x: \"Positive\" if float(x) > 0 else \"Negative\")\n",
    ")\n",
    "\n",
    "df_reports[\"report_and_mets_label\"] = (\n",
    "    \"Report:\\n\" + \n",
    "    df_reports[\"combined_reports\"] + \n",
    "    \"\\n\\nMetastases classification:\\n\" + \n",
    "    df_reports[\"image_ct___1\"]\n",
    "    # df_reports[\"image_ct___2\"].apply(lambda x: \"Positive\" if float(x) > 0 else \"Negative\")\n",
    ")\n",
    "\n",
    "# drop reports that have NaN in reports column\n",
    "df_reports = df_reports.dropna(subset=[\"report_and_frac_label\", \"report_and_mets_label\"])\n",
    "\n",
    "df_reports.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGPipeline:\n",
    "    def __init__(self, \n",
    "                 embedding_model_name=\"sentence-transformers/all-mpnet-base-v2\",\n",
    "                 llm_model_name=\"google/flan-t5-large\",  # Example seq2seq model\n",
    "                 device=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n",
    "        \n",
    "        print(f\"Initializing RAG system on {device}\")\n",
    "        \n",
    "        self.embeddings = HuggingFaceEmbeddings(model_name=embedding_model_name)\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=500,\n",
    "            chunk_overlap=50\n",
    "        )\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "            llm_model_name,\n",
    "            trust_remote_code=True\n",
    "        )\n",
    "        \n",
    "        # load LLM\n",
    "        print(\"Loading language model...\")\n",
    "        model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "            llm_model_name,\n",
    "            torch_dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",
    "            device_map=\"auto\",\n",
    "            trust_remote_code=True,\n",
    "            load_in_8bit=True if device == \"cuda\" else False\n",
    "        )\n",
    "        \n",
    "        # text gen pipeline\n",
    "        pipe = pipeline(\n",
    "            \"text2text-generation\",\n",
    "            model=model,\n",
    "            tokenizer=self.tokenizer,\n",
    "            max_length=512,\n",
    "            temperature=0.7,\n",
    "            top_p=0.95,\n",
    "            # device=device,\n",
    "            do_sample=True\n",
    "        )\n",
    "        \n",
    "        self.llm = HuggingFacePipeline(pipeline=pipe)\n",
    "        self.vectorstore = None\n",
    "        self.qa_chain = None\n",
    "\n",
    "    def _create_prompt(self, context, question):\n",
    "        return f\"\"\"Answer the following question based on the given context.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "    def load_data(self, df, text_column):\n",
    "\n",
    "        loader = DataFrameLoader(df, page_content_column=text_column)\n",
    "        documents = loader.load()\n",
    "        \n",
    "        texts = self.text_splitter.split_documents(documents)\n",
    "        self.vectorstore = FAISS.from_documents(texts, self.embeddings)\n",
    "        \n",
    "        self.qa_chain = RetrievalQA.from_chain_type(\n",
    "            llm=self.llm,\n",
    "            chain_type=\"stuff\",\n",
    "            retriever=self.vectorstore.as_retriever(\n",
    "                search_kwargs={\"k\": 3}\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        return f\"Loaded {len(texts)} text chunks into the vector store\"\n",
    "\n",
    "    def query(self, question):\n",
    "        \"\"\"query RAG system\"\"\"\n",
    "        if self.qa_chain is None:\n",
    "            raise ValueError(\"Please load data first\")\n",
    "        \n",
    "        # retrieve relevant docs\n",
    "        docs = self.vectorstore.similarity_search(question, k=3)\n",
    "        context = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "        \n",
    "        prompt = self._create_prompt(context, question)\n",
    "        \n",
    "        response = self.llm(prompt)\n",
    "        \n",
    "        return response[0]['generated_text'] if isinstance(response, list) else response\n",
    "\n",
    "    def batch_query(self, questions):\n",
    "        \"\"\"be able to handle multiple reports at once\"\"\"\n",
    "        return [self.query(q) for q in questions]\n",
    "\n",
    "    def similarity_search(self, query, k=3):\n",
    "        if self.vectorstore is None:\n",
    "            raise ValueError(\"Please load data first\")\n",
    "        return self.vectorstore.similarity_search(query, k=k)\n",
    "\n",
    "    def save_vectorstore(self, path):\n",
    "        \"\"\"save FAISS vector database locally\"\"\"\n",
    "        if self.vectorstore:\n",
    "            self.vectorstore.save_local(path)\n",
    "            print(f\"Vector database saved to {path}\")\n",
    "        else:\n",
    "            raise ValueError(\"No vector store to save\")\n",
    "\n",
    "    def load_vectorstore(self, path):\n",
    "        \"\"\"Load a saved FAISS vector store\"\"\"\n",
    "        print(f\"Loading vector store from {path}\")\n",
    "        self.vectorstore = FAISS.load_local(path, self.embeddings)\n",
    "        \n",
    "        self.qa_chain = RetrievalQA.from_chain_type(\n",
    "            llm=self.llm,\n",
    "            chain_type=\"stuff\",\n",
    "            retriever=self.vectorstore.as_retriever(\n",
    "                search_kwargs={\"k\": 3}\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing RAG system on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer...\n",
      "Loading language model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1075279/1967846821.py:57: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
      "  self.llm = HuggingFacePipeline(pipeline=pipe)\n"
     ]
    }
   ],
   "source": [
    "rag = RAGPipeline(\n",
    "        # embedding_model_name=\"sentence-transformers/all-mpnet-base-v2\",\n",
    "        # llm_model_name=\"meta-llama/Llama-2-7b-chat-hf\"  # Or any other causal LM\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Loaded 22227 text chunks into the vector store\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading data...\")\n",
    "result = rag.load_data(df_reports, text_column='report_and_frac_label')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: ...\n"
     ]
    }
   ],
   "source": [
    "input = \"...\"\n",
    "print(f\"Input: {input}\")\n",
    "output = rag.query(input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Output: Report\n"
     ]
    }
   ],
   "source": [
    "print(f\"LLM Output: {output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch reports & LLM labels\n",
    "inputs = [\n",
    "    \"...\"\n",
    "]\n",
    "outputs = rag.batch_query(inputs)\n",
    "\n",
    "for i, o in zip(inputs, outputs):\n",
    "    print(f\"\\Input: {i}\")\n",
    "    print(f\"Output: {o}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
